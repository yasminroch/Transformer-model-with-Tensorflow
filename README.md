# Transformer-model-with-Tensorflow

## Pontos Positivos:
* Estrutura modular do código: O tutorial segue uma estrutura bem organizada, permitindo que os conceitos e blocos de código sejam compreendidos de maneira incremental.
* Bom desempenho com hardware adequado: Em máquinas com boa capacidade de processamento (GPUs ou TPUs), o modelo apresenta um bom desempenho de treinamento, reduzindo o tempo necessário para atingir resultados satisfatórios.
* Abordagem compreensível: O tutorial é claro e progressivo

## Pontos Negativos:
* Alto consumo de recursos: Mesmo com otimizações, o treinamento de um modelo Transformer demanda uma grande quantidade de recursos computacionais, especialmente em máquinas sem GPU, o que pode tornar o processo lento ou estourar a memória.
* Tempo de treinamento longo: O tempo de treinamento foi bastante longo.
* Dependência de dados pré-processados: O tutorial já vem com um dataset pré-processado, o que facilita o aprendizado, mas limita a personalização e experimentação com dados próprios.
* Escalabilidade: Enquanto o tutorial é ótimo para aprendizado, a implementação prática em sistemas de larga escala exigiria modificações significativas e mais otimizações de performance.